{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance comparison\n",
    "Presented by Chiyoung Ahn (https://github.com/chiyahn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider minimizing following objective function\n",
    "$$\n",
    "f(x) = \\sum_{i=1}^N \\left[ (x_i - m_i)^2 + \\log(x_i) \\right]\n",
    "$$\n",
    "with a fixed $m$ and some fairly large `N` by limited-memory BFGS (LBFGS):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "using NLopt, BenchmarkTools, ForwardDiff, NLSolversBase, DiffResults, Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 10000\n",
    "m = range(2,5,length = N)\n",
    "f(x) = sum((x .- m).^2) + sum(log.(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Vanilla `ForwardDiff.jl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.719 s (134741 allocations: 14.77 GiB)\n",
      "got 11933.964915391838 after 9 iterations (returned SUCCESS)\n"
     ]
    }
   ],
   "source": [
    "function g!(G::Vector, x::Vector)\n",
    "    ForwardDiff.gradient!(G, f, x)\n",
    "end\n",
    "\n",
    "function fg!(x::Vector, grad::Vector)\n",
    "    if length(grad) > 0 # gradient of f(x)\n",
    "        g!(grad, x)\n",
    "    end\n",
    "    f(x)\n",
    "end\n",
    "# define the optimization problem\n",
    "opt = Opt(:LD_LBFGS, N) # 2 indicates the length of `x`\n",
    "lower_bounds!(opt, fill(1.0, N)) # find `x` above 0\n",
    "min_objective!(opt, fg!) # specifies that optimization problem is on minimization\n",
    "\n",
    "# solve the optimization problem\n",
    "(minf,minx,ret) = @btime optimize(opt, fill(1.0, N))\n",
    "numevals = opt.numevals # the number of function evaluations\n",
    "println(\"got $minf after $numevals iterations (returned $ret)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. `NLoptAdapter` with autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NLoptAdapter"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See nlopt-tutorial.ipynb\n",
    "struct NLoptAdapter{T} <: Function where T <: AbstractObjective\n",
    "    nlsolver_base::T\n",
    "end\n",
    "\n",
    "# implement fg!; note that the order is reversed\n",
    "(adapter::NLoptAdapter)(x, df) = adapter.nlsolver_base.fdf(df, x)\n",
    "(adapter::NLoptAdapter)(result, x, jacobian_transpose) = adapter.nlsolver_base.fdf(result, jacobian_transpose', x)\n",
    "\n",
    "# constructors\n",
    "NLoptAdapter(f, x, autodiff) = NLoptAdapter(OnceDifferentiable(f, x, autodiff = autodiff))\n",
    "NLoptAdapter(f!, x::Vector, F::Vector, autodiff) = NLoptAdapter(OnceDifferentiable(f!, x, F, autodiff = autodiff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.385 s (134615 allocations: 14.76 GiB)\n",
      "got 11933.964915391838 after 9 iterations (returned SUCCESS)\n"
     ]
    }
   ],
   "source": [
    "f_opt = NLoptAdapter(f, zeros(N), :forward)\n",
    "\n",
    "# define the optimization problem\n",
    "opt = Opt(:LD_LBFGS, N) # 2 indicates the length of `x`\n",
    "lower_bounds!(opt, fill(0.0, N)) # find `x` above -2.0\n",
    "min_objective!(opt, f_opt) # specifies that optimization problem is on minimization\n",
    "\n",
    "# solve the optimization problem\n",
    "(minf,minx,ret) = @btime optimize(opt, fill(1.0, N))\n",
    "numevals = opt.numevals # the number of function evaluations\n",
    "println(\"got $minf after $numevals iterations (returned $ret)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. `NLoptAdapter` with numerical gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  21.224 s (3295091 allocations: 29.88 GiB)\n",
      "got 11933.964915391842 after 10 iterations (returned FTOL_REACHED)\n"
     ]
    }
   ],
   "source": [
    "f_opt = NLoptAdapter(f, zeros(N), :finite)\n",
    "\n",
    "# define the optimization problem\n",
    "opt = Opt(:LD_LBFGS, N) # 2 indicates the length of `x`\n",
    "lower_bounds!(opt, fill(0.0, N)) # find `x` above -2.0\n",
    "min_objective!(opt, f_opt) # specifies that optimization problem is on minimization\n",
    "\n",
    "# solve the optimization problem\n",
    "(minf,minx,ret) = @btime optimize(opt, fill(1.0, N))\n",
    "numevals = opt.numevals # the number of function evaluations\n",
    "println(\"got $minf after $numevals iterations (returned $ret)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mighty `Flux.jl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9.944 ms (3755 allocations: 10.61 MiB)\n",
      "got 11933.964915391838 after 9 iterations (returned SUCCESS)\n"
     ]
    }
   ],
   "source": [
    "using Flux\n",
    "using Flux.Tracker: gradient_\n",
    "\n",
    "function fg!(x::Vector, grad::Vector)\n",
    "    val = f(x)\n",
    "    grad[:] = gradient_(f, x)[1]\n",
    "    return val\n",
    "end\n",
    "# define the optimization problem\n",
    "opt = Opt(:LD_LBFGS, N) # 2 indicates the length of `x`\n",
    "lower_bounds!(opt, fill(1.0, N)) # find `x` above 0\n",
    "min_objective!(opt, fg!) # specifies that optimization problem is on minimization\n",
    "\n",
    "# solve the optimization problem\n",
    "(minf,minx,ret) = @btime optimize(opt, fill(1.0, N))\n",
    "numevals = opt.numevals # the number of function evaluations\n",
    "println(\"got $minf after $numevals iterations (returned $ret)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
